{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1bvRsjJXi7JPX0YLrRFJfch7LMPLP4ceF?usp=sharing)"
      ],
      "metadata": {
        "id": "GJEwlBpGU0wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Meta's Llama 3.2 Vision 11B\n",
        "\n",
        "Notebook by [Build Fast with AI](https://www.buildfastwithai.com/genai-course)"
      ],
      "metadata": {
        "id": "bGHvPmgBUvNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-bvvcSnKCGG",
        "outputId": "bde00188-6709-492d-cf54-b476e4a86aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/376.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Image URL"
      ],
      "metadata": {
        "id": "gN48zpFQVMtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "together = OpenAI(api_key=userdata.get(\"TOGETHER_API_KEY\"),\n",
        "                  base_url=\"https://api.together.xyz/v1\")\n",
        "\n",
        "response = together.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-Vision-Free\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\",\n",
        "          \"content\": [\n",
        "                      {\"type\": \"text\",\n",
        "                        \"text\": \"Describe the image\"},\n",
        "                      {\"type\": \"image_url\",\n",
        "                        \"image_url\": { \"url\": \"https://newvision-media.s3.amazonaws.com/cms/4040184f-4412-4775-980f-d2df40139bd3.jpg\"}}\n",
        "                     ]\n",
        "        }])\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux4E6b5NKEKt",
        "outputId": "2cd408ee-1c01-45f6-e3ff-85438bc28468"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image depicts a car being transported by a horse-drawn cart. The white sedan is tilted forward on the cart, with a portion of the rear end visible. A man in a white shirt and black pants leads the horse, which is pulling the cart and car on a paved road. The horse is tan with a white face and is adorned with a bridle and harness.\n",
            "\n",
            "In the background, a beige brick wall and a large tree are visible, set against an overcast sky. The image provides a glimpse into a unique mode of transportation, where a horse is used to haul a car, highlighting the resourcefulness and adaptability of individuals in certain circumstances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "with open(\"population_chart.jpg\", \"rb\") as image_file:\n",
        "    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "response = together.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-Vision-Free\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"Please analyse this graph\"},\n",
        "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_string}\"}}\n",
        "        ]}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPOnPWO-UD_E",
        "outputId": "93f682a3-1d62-4213-96b1-229f30de8c0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attached graph portrays the population of India from 1950 to 2100, broken down by age groups: ages 0-20, 21-64, and 65+. The graph's y-axis represents the population in millions, while the x-axis represents the year. \n",
            "\n",
            "The blue section represents the 21-64 age group, which is the largest portion of the population, spanning from 1950 to 2100. This age group is growing every year. \n",
            "\n",
            "The yellow section represents the age 0-20 population, which is also increasing over time. \n",
            "\n",
            "The pink section represents the 65+ population, which is also growing over time. However, the growth rate is slower than the 21-64 age group.\n",
            "\n",
            "According to the graph, India's population is expected to increase from 1.7 billion in 2020 to 1.8 billion by 2050 and peak in 2060 at 1.9 billion before declining afterwards. \n",
            "\n",
            "The 21-64 age group is expected to reach a peak of 990 million by 2060 and then decline, while the 0-20 age group is expected to peak at 431 million by 2050 and then decline. \n",
            "\n",
            "The 65+ age group is expected to peak at 256 million by 2060 and then decline. \n",
            "\n",
            "Overall, the graph provides a comprehensive overview of India's population distribution by age group over time, highlighting the country's demographic trends and projections. \n",
            "\n",
            "*Answer*: India's population distribution by age (1950-2100).\n"
          ]
        }
      ]
    }
  ]
}