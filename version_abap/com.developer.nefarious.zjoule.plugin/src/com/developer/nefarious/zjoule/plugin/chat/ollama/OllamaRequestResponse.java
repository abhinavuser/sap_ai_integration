package com.developer.nefarious.zjoule.plugin.chat.ollama;

import com.google.gson.annotations.SerializedName;

/**
 * Represents the response received from the Ollama API after a chat request.
 * <p>
 * This class contains details about the generated chat response, including the
 * model used, message content, completion status, evaluation metrics, and timing details.
 * It is designed for serialization and deserialization using the {@link com.google.gson.Gson} library.
 * </p>
 */
public class OllamaRequestResponse {

    /** The name of the AI model used for generating the response. */
    private String model;

    /** The timestamp when the response was created. */
    @SerializedName("created_at")
    private String createdAt;

    /** The chat message generated by the AI model. */
    private OllamaChatMessage message;

    /** The reason the chat request was completed (e.g., "stop", "length", etc.). */
    @SerializedName("done_reason")
    private String doneReason;

    /** Indicates whether the response generation is complete. */
    private boolean done;

    /** The total duration (in milliseconds) taken to generate the response. */
    @SerializedName("total_duration")
    private long totalDuration;

    /** The duration (in milliseconds) taken to load the model before response generation. */
    @SerializedName("load_duration")
    private long loadDuration;

    /** The number of tokens processed in the prompt evaluation phase. */
    @SerializedName("prompt_eval_count")
    private int promptEvalCount;

    /** The duration (in milliseconds) taken to evaluate the prompt. */
    @SerializedName("prompt_eval_duration")
    private long promptEvalDuration;

    /** The number of tokens processed in the main evaluation phase. */
    @SerializedName("eval_count")
    private int evalCount;

    /** The duration (in milliseconds) taken for the main evaluation phase. */
    @SerializedName("eval_duration")
    private long evalDuration;

    /**
     * Retrieves the name of the AI model used.
     *
     * @return the model name as a {@link String}.
     */
    public String getModel() {
        return model;
    }

    /**
     * Sets the name of the AI model used.
     *
     * @param model the model name to set.
     */
    public void setModel(final String model) {
        this.model = model;
    }

    /**
     * Retrieves the timestamp when the response was created.
     *
     * @return the creation timestamp as a {@link String}.
     */
    public String getCreatedAt() {
        return createdAt;
    }

    /**
     * Sets the timestamp when the response was created.
     *
     * @param createdAt the creation timestamp to set.
     */
    public void setCreatedAt(final String createdAt) {
        this.createdAt = createdAt;
    }

    /**
     * Retrieves the generated chat message.
     *
     * @return the chat message as an {@link OllamaChatMessage}.
     */
    public OllamaChatMessage getMessage() {
        return message;
    }

    /**
     * Sets the generated chat message.
     *
     * @param message the chat message to set.
     */
    public void setMessage(final OllamaChatMessage message) {
        this.message = message;
    }

    /**
     * Retrieves the reason why the response generation was completed.
     *
     * @return the completion reason as a {@link String}.
     */
    public String getDoneReason() {
        return doneReason;
    }

    /**
     * Sets the reason why the response generation was completed.
     *
     * @param doneReason the completion reason to set.
     */
    public void setDoneReason(final String doneReason) {
        this.doneReason = doneReason;
    }

    /**
     * Checks if the response generation is complete.
     *
     * @return {@code true} if the response is fully generated, {@code false} otherwise.
     */
    public boolean isDone() {
        return done;
    }

    /**
     * Sets whether the response generation is complete.
     *
     * @param done {@code true} if the response is fully generated, {@code false} otherwise.
     */
    public void setDone(final boolean done) {
        this.done = done;
    }

    /**
     * Retrieves the total duration taken to generate the response.
     *
     * @return the total duration in milliseconds.
     */
    public long getTotalDuration() {
        return totalDuration;
    }

    /**
     * Sets the total duration taken to generate the response.
     *
     * @param totalDuration the total duration in milliseconds.
     */
    public void setTotalDuration(final long totalDuration) {
        this.totalDuration = totalDuration;
    }

    /**
     * Retrieves the duration taken to load the model before response generation.
     *
     * @return the load duration in milliseconds.
     */
    public long getLoadDuration() {
        return loadDuration;
    }

    /**
     * Sets the duration taken to load the model before response generation.
     *
     * @param loadDuration the load duration in milliseconds.
     */
    public void setLoadDuration(final long loadDuration) {
        this.loadDuration = loadDuration;
    }

    /**
     * Retrieves the number of tokens evaluated in the prompt phase.
     *
     * @return the prompt evaluation token count.
     */
    public int getPromptEvalCount() {
        return promptEvalCount;
    }

    /**
     * Sets the number of tokens evaluated in the prompt phase.
     *
     * @param promptEvalCount the prompt evaluation token count to set.
     */
    public void setPromptEvalCount(final int promptEvalCount) {
        this.promptEvalCount = promptEvalCount;
    }

    /**
     * Retrieves the duration taken to evaluate the prompt.
     *
     * @return the prompt evaluation duration in milliseconds.
     */
    public long getPromptEvalDuration() {
        return promptEvalDuration;
    }

    /**
     * Sets the duration taken to evaluate the prompt.
     *
     * @param promptEvalDuration the prompt evaluation duration in milliseconds.
     */
    public void setPromptEvalDuration(final long promptEvalDuration) {
        this.promptEvalDuration = promptEvalDuration;
    }

    /**
     * Retrieves the number of tokens evaluated in the main evaluation phase.
     *
     * @return the evaluation token count.
     */
    public int getEvalCount() {
        return evalCount;
    }

    /**
     * Sets the number of tokens evaluated in the main evaluation phase.
     *
     * @param evalCount the evaluation token count to set.
     */
    public void setEvalCount(final int evalCount) {
        this.evalCount = evalCount;
    }

    /**
     * Retrieves the duration taken for the main evaluation phase.
     *
     * @return the evaluation duration in milliseconds.
     */
    public long getEvalDuration() {
        return evalDuration;
    }

    /**
     * Sets the duration taken for the main evaluation phase.
     *
     * @param evalDuration the evaluation duration in milliseconds.
     */
    public void setEvalDuration(final long evalDuration) {
        this.evalDuration = evalDuration;
    }
}